# Model Categories and Descriptions

## Overview

There are up to **hundreds** of optimized pre-trained models for on-device ready-to-deploy, available in AI platform hubs like Hugging Face, GitHub Model Zoos, TensorFlow & PyTorch Hub, and more.

The table below categorizes some of these models based on their primary functionalities:


| Category | Model | Description | Reference |
|---|---|---|---|
| **Language** | Whisper | General-purpose speech recognition model | [Whisper on Hugging Face](https://huggingface.co/openai/whisper) |
| | Baichuan | Large language model | [Baichuan on Hugging Face](https://huggingface.co/baichuan-inc/Baichuan-13B-Base) |
| | huggingface_wavlm_base_plus | Audio language model for speech recognition | [WavLM on Hugging Face](https://huggingface.co/microsoft/wavlm-base-plus) |
| | whisper_asr | Speech recognition model | [Whisper ASR on GitHub](https://github.com/openai/whisper) |
| | trocr | Text recognition in images | [TrOCR on Hugging Face](https://huggingface.co/microsoft/trocr-base) |
| **Audio** | Whisper | Speech-to-text | [Whisper on Hugging Face](https://huggingface.co/openai/whisper) |
| | huggingface_wavlm_base_plus | Audio language model for speech recognition | [WavLM on Hugging Face](https://huggingface.co/microsoft/wavlm-base-plus) |
| | whisper_asr | Speech recognition model | [Whisper ASR on GitHub](https://github.com/openai/whisper) |
| **Vision** | aotgan | Image generation | [AOT-GAN on GitHub](https://github.com/researchmm/AOT-GAN) |
| | convnext_tiny | Vision transformer for image classification | [ConvNeXt on Hugging Face](https://huggingface.co/facebook/convnext-tiny-224) |
| | ddrnet23_slim | Image segmentation | [DDRNet on GitHub](https://github.com/ydhongHIT/DDRNet) |
| | deeplabv3_resnet50 | Semantic image segmentation | [DeepLabV3 on TensorFlow Hub](https://tfhub.dev/tensorflow/deeplabv3/1) |
| | densenet121 | Image classification | [DenseNet on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_densenet/) |
| | detr_resnet101 | Object detection | [DETR on GitHub](https://github.com/facebookresearch/detr) |
| | detr_resnet101_dc5 | Object detection | [DETR on GitHub](https://github.com/facebookresearch/detr) |
| | detr_resnet50 | Object detection | [DETR on GitHub](https://github.com/facebookresearch/detr) |
| | detr_resnet50_dc5 | Object detection | [DETR on GitHub](https://github.com/facebookresearch/detr) |
| | esrgan | Image super-resolution | [ESRGAN on GitHub](https://github.com/xinntao/ESRGAN) |
| | facebook_denoiser | Image denoising | [Denoiser on GitHub](https://github.com/facebookresearch/denoiser) |
| | fcn_resnet50 | Semantic image segmentation | [FCN on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_fcn_resnet50/) |
| | googlenet | Image classification | [GoogLeNet on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_googlenet/) |
| | lama_dilated | Image inpainting | [LaMa on GitHub](https://github.com/saic-mdal/lama) |
| | litehrnet | Image segmentation | [Lite-HRNet on GitHub](https://github.com/HRNet/Lite-HRNet) |
| | mediapipe_face | Face detection | [MediaPipe Face on Google AI](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html) |
| | mediapipe_hand | Hand detection | [MediaPipe Hand on Google AI](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html) |
| | mnasnet05 | Image classification | [MnasNet on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_mnasnet/) |
| | mobiledet | Object detection | [MobileDet on TensorFlow Hub](https://tfhub.dev/s?q=mobiledet) |
| | mobilenet_v3_small | Image classification | [MobileNetV3 on TensorFlow Hub](https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5) |
| | openpose | Human pose estimation | [OpenPose on GitHub](https://github.com/CMU-Perceptual-Computing-Lab/openpose) |
| | QuickSRNet_Large | Image super-resolution | [QuickSRNet on GitHub](https://github.com/QuickSRNet/QuickSRNet) |
| | real_esrgan_general_x4v3 | Image super-resolution | [Real-ESRGAN on GitHub](https://github.com/xinntao/Real-ESRGAN) |
| | real_esrgan_x4plus | Image super-resolution | [Real-ESRGAN on GitHub](https://github.com/xinntao/Real-ESRGAN) |
| | resnet_2plus1d | Video classification | [ResNet-2+1D on PyTorch Hub](https://pytorch.org/hub/facebookresearch_pytorchvideo_resnet/) |
| | resnet_3d | Video classification | [ResNet-3D on PyTorch Hub](https://pytorch.org/hub/facebookresearch_pytorchvideo_resnet/) |
| | ResNeXt50 | Image classification | [ResNeXt on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnext/) |
| | sam | Segmentation | [SAM on GitHub](https://github.com/facebookresearch/segment-anything) |
| | Sesr_m3 | Image super-resolution | [SESR on GitHub](https://github.com/SESR/SESR) |
| | shufflenet_v2 | Image classification | [ShuffleNetV2 on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_shufflenet_v2/) |
| | sinet | Image segmentation | [SINet on GitHub](https://github.com/DengPingFan/SINet) |
| | squeezenet_1 | Image classification | [SqueezeNet on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_squeezenet/) |
| | stylegan2 | Image generation | [StyleGAN2 on GitHub](https://github.com/NVlabs/stylegan2) |
| | unet_segmentation | Image segmentation | [UNet on GitHub](https://github.com/milesial/Pytorch-UNet) |
| | vit | Image classification | [ViT on Hugging Face](https://huggingface.co/google/vit-base-patch16-224) |
| | wideresnet50 | Image classification | [WideResNet on PyTorch Hub](https://pytorch.org/hub/pytorch_vision_wideresnet/) |
| | xisr | Image super-resolution | [XISR on GitHub](https://github.com/XISR/XISR) |
| | yolov6 | Object detection | [YOLOv6 on GitHub](https://github.com/meituan/YOLOv6) |
| | yolov7 | Object detection | [YOLOv7 on GitHub](https://github.com/WongKinYiu/yolov7) |
| | yolov8_det | Object detection | [YOLOv8 on GitHub](https://github.com/ultralytics/yolov8) |
| | yolov8_seg | Object detection and segmentation | [YOLOv8 on GitHub](https://github.com/ultralytics/yolov8) |
| **Multimodality** | ControlNet | Fine control over image generation | [ControlNet on GitHub](https://github.com/lllyasviel/ControlNet) |
| | Stable Diffusion | Text-to-image generation | [Stable Diffusion on Hugging Face](https://huggingface.co/CompVis/stable-diffusion-v-1-4) |
| | Mediapipe_pose | Human pose estimation | [MediaPipe Pose on Google AI](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html) |


## Resources

**Model Zoos:**
- [Model Zoo](https://modelzoo.co/)
- [Papers with Code](https://paperswithcode.com/)
- [Onnx Model Zoo](https://github.com/onnx/models)
- [LiteRT Pre-trained models](https://ai.google.dev/edge/litert/models/trained)
- [TensorFlow Model Garden](https://github.com/tensorflow/models/tree/master)
- [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide)
- [Pytorch Model Zoo](https://pytorch.org/serve/model_zoo.html)
- [MXNet Model Zoo](https://mxnet.apache.org/versions/1.1.0/model_zoo/index.html)
- [Edge Impulse Model Zoo](https://www.edgeimpulse.com/)
- [OpenVINO Model Zoo](https://github.com/openvinotoolkit/open_model_zoo)
- [Deciâ€™s Model Zoo](https://deci.ai/modelzoo/)
- [NVIDIA TAO](https://developer.nvidia.com/tao-toolkit)
- [Jetson Model Zoo and Community Projects](https://developer.nvidia.com/embedded/community/jetson-projects)
- [Magenta](https://github.com/magenta/magenta/tree/main/magenta/models/arbitrary_image_stylization)
- [Awesome-CoreML-Models Public](https://github.com/likedan/Awesome-CoreML-Models)
- [Pinto Models](https://github.com/PINTO0309/PINTO_model_zoo)

**Deployment Frameworks/Toolkits**
- [TensorFlow Lite](https://www.tensorflow.org/lite)
- [ONNX Runtime](https://onnxruntime.ai/)
- [TensorRT](https://developer.nvidia.com/tensorrt)
- [OpenVINO Toolkit](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)
- [Core ML](https://developer.apple.com/documentation/coreml)
- [TFLite Model Maker](https://www.tensorflow.org/lite/models/modify/model_maker)
- [AWS SageMaker Neo](https://aws.amazon.com/sagemaker/neo/)
- [Google Cloud AI Platform](https://cloud.google.com/ai-platform)
- [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/)
- [Edge Impulse](https://www.edgeimpulse.com/)
- [Apache TVM](https://tvm.apache.org/)
- [MLIR](https://mlir.llvm.org/)
- [NVIDIA Triton Inference Server](https://developer.nvidia.com/nvidia-triton-inference-server)


**Companies**
- [Hugging Face](https://huggingface.co/)
- [Google AI Hub](https://aihub.cloud.google.com/)
    - [Google/Android](https://ai.google.dev/edge)
- [Apple](https://www.apple.com/ai/)
- [NVIDIA](https://www.nvidia.com/en-us/research/)
- [Meta (Facebook)](https://ai.facebook.com/)
    - [Facebook AI Research (FAIR) Models](https://github.com/facebookresearch)
- [Microsoft (MS)](https://www.microsoft.com/en-us/research/)
- [Amazon Web Services (AWS)](https://aws.amazon.com/machine-learning/)
- [Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/overview.html)
- [ARM](https://www.arm.com/solutions/artificial-intelligence)
- [STMicroelectronics](https://www.st.com/content/st_com/en/stm32-ai.html)
- [Edge Impulse](https://www.edgeimpulse.com/)
- [Qualcomm](https://www.qualcomm.com/research/artificial-intelligence)
- [Azure AI Gallery](https://gallery.azure.ai/)
- [IBM Model Asset Exchange](https://developer.ibm.com/exchanges/models/)
- [Baidu AI Open Model Zoo](https://ai.baidu.com/tech/modelzoo)
- [Alibaba Cloud AI Model Marketplace](https://www.alibabacloud.com/solutions/ai)
- [Tencent AI Open Platform](https://ai.qq.com/)
- [Samsung AI](https://research.samsung.com/artificial-intelligence)

**Blogs:**

- [13 Free Resources and Model Zoos for Deep Learning and Computer Vision Models](https://www.edge-ai-vision.com/2022/04/13-free-resources-and-model-zoos-for-deep-learning-and-computer-vision-models/)
- [LiteRT Models](https://ai.google.dev/edge/litert/models/trained)
- [Amazon SageMaker and Qualcomm AI Hub](https://aws.amazon.com/blogs/machine-learning/train-optimize-and-deploy-models-on-edge-devices-using-amazon-sagemaker-and-qualcomm-ai-hub/)
- [Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/unit9/intro_to_model_optimization)
- [Apple Foundation Models](https://machinelearning.apple.com/research/introducing-apple-foundation-models)